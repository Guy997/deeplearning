{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/callum/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n",
      "Using cuDNN version 7005 on context None\n",
      "Preallocating 1602/2002 Mb (0.800000) on cuda0\n",
      "Mapped name None to device cuda0: GeForce GTX 860M (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import ZeroPadding2D, Conv2D\n",
    "from keras.layers import MaxPooling2D, BatchNormalization\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr\n",
    "\n",
    "def ConvBlock(layers, filters):\n",
    "        for i in range(layers):\n",
    "            model.add(ZeroPadding2D((1, 1)))\n",
    "            model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu'))  # Keras2\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "def FCBlock():\n",
    "        model.add(Dense(4096, activation='relu'))\n",
    "        model.add(Dropout(0.))\n",
    "        #model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(vgg_preprocess, input_shape=(3,224,224), output_shape=(3,224,224)))\n",
    "ConvBlock(2, 64)\n",
    "ConvBlock(2, 128)\n",
    "ConvBlock(3, 256)\n",
    "ConvBlock(3, 512)\n",
    "ConvBlock(3, 512)\n",
    "\n",
    "model.add(Flatten())\n",
    "FCBlock()\n",
    "FCBlock()\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "model.load_weights('fastai/models/vgg_by_hand.h5')\n",
    "for layer in model.layers: layer.trainable=False\n",
    "model.pop()\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.load_weights('models/dogscats2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropout_indxs = [index for index,layer in enumerate(model.layers) \n",
    "                     if type(layer) is Dropout][::-1]\n",
    "fake_model = Sequential(model.layers[:35])\n",
    "#fake_model.add(BatchNormalization())\n",
    "fake_model.add(model.layers[35])\n",
    "fake_model.add(model.layers[36])\n",
    "fake_model.add(BatchNormalization())\n",
    "fake_model.add(model.layers[-1])\n",
    "for layer in fake_model.layers[33:]:\n",
    "    layer.trainable=True\n",
    "#model.optimizer.lr.set_value(0.0001)\n",
    "fake_model.compile(optimizer=Adam(lr=.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers = model.layers[:31]\n",
    "conv_model = Sequential(conv_layers)\n",
    "fc_layers = model.layers[31:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='data/dogscats'\n",
    "train_path=path+\"/train\"\n",
    "valid_path=path+\"/valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Get data\n",
    "from keras.preprocessing import image\n",
    "\n",
    "gen = image.ImageDataGenerator()\n",
    "batch_size=4\n",
    "\n",
    "train_batches = gen.flow_from_directory(train_path, target_size=(224,224), class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "val_batches = gen.flow_from_directory(valid_path, target_size=(224,224), class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "classes = list(iter(train_batches.class_indices)) # get a list of all the class labels\n",
    "\n",
    "for c in train_batches.class_indices:\n",
    "    classes[train_batches.class_indices[c]] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = int(np.ceil(train_batches.samples/batch_size))\n",
    "validation_steps = int(np.ceil(val_batches.samples/batch_size))\n",
    "\n",
    "# trn_classes = train_batches.classes\n",
    "# val_classes = val_batches.classes\n",
    "# val_features = conv_model.predict_generator(val_batches, validation_steps)\n",
    "# trn_features = conv_model.predict_generator(train_batches, steps_per_epoch)\n",
    "# trn_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in fake_model.layers[33:]:\n",
    "#    layer.trainable=True\n",
    "#model.optimizer.lr.set_value(0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit FC Layers\n",
    "\n",
    "#fc_model.fit(trn_features, trn_labels, epochs=1, batch_size=batch_size, validation_data=(val_features, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "GpuArrayException",
     "evalue": "cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory\nApply node that caused the error: GpuDot22(InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{(i0 + (i1 * i2))}(i1, i2, i3)) + (i4 * Composite{(i0 + (i1 * i2))}(i1, i2, i3) * sgn(i5)))}}[(0, 1)]<gpuarray>.0)\nToposort index: 645\nInputs types: [GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix)]\nInputs shapes: [(25088, 4), (4, 4096)]\nInputs strides: [(4, 100352), (16384, 4)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)]<gpuarray>(InplaceGpuDimShuffle{x,x}.0, training/Adam/variable, InplaceGpuDimShuffle{x,x}.0, GpuDot22.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/keras/optimizers.py\", line 73, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 1237, in gradients\n    return T.grad(loss, variables)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 605, in grad\n    grad_dict, wrt, cost_name)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1371, in _populate_grad_dict\n    rval = [access_grad_cache(elem) for elem in wrt]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1326, in access_grad_cache\n    term = access_term_cache(node)[idx]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1021, in access_term_cache\n    output_grads = [access_grad_cache(var) for var in node.outputs]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1326, in access_grad_cache\n    term = access_term_cache(node)[idx]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1162, in access_term_cache\n    new_output_grads)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/keras/optimizers.py\", line 73, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 1237, in gradients\n    return T.grad(loss, variables)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 605, in grad\n    grad_dict, wrt, cost_name)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1371, in _populate_grad_dict\n    rval = [access_grad_cache(elem) for elem in wrt]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1326, in access_grad_cache\n    term = access_term_cache(node)[idx]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1021, in access_term_cache\n    output_grads = [access_grad_cache(var) for var in node.outputs]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1326, in access_grad_cache\n    term = access_term_cache(node)[idx]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1162, in access_term_cache\n    new_output_grads)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGpuArrayException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9fd6edadf04c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m fake_model.fit_generator(train_batches, steps_per_epoch=int(np.ceil(train_batches.samples/batch_size)), epochs=1,\n\u001b[0;32m----> 5\u001b[0;31m                 validation_data=val_batches, validation_steps=int(np.ceil(val_batches.samples/batch_size)))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#model.fit_generator(train_batches, samples_per_epoch=train_batches.samples, epochs=1, validation_data=val_batches, validation_steps=val_batches.samples)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/callum/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/callum/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1225\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/callum/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/callum/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/callum/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/callum/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/callum/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/callum/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/callum/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpygpu/gpuarray.pyx\u001b[0m in \u001b[0;36mpygpu.gpuarray.pygpu_empty\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpygpu/gpuarray.pyx\u001b[0m in \u001b[0;36mpygpu.gpuarray.array_empty\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mGpuArrayException\u001b[0m: cuMemAlloc: CUDA_ERROR_OUT_OF_MEMORY: out of memory\nApply node that caused the error: GpuDot22(InplaceGpuDimShuffle{1,0}.0, GpuElemwise{Composite{((i0 * Composite{(i0 + (i1 * i2))}(i1, i2, i3)) + (i4 * Composite{(i0 + (i1 * i2))}(i1, i2, i3) * sgn(i5)))}}[(0, 1)]<gpuarray>.0)\nToposort index: 645\nInputs types: [GpuArrayType<None>(float32, matrix), GpuArrayType<None>(float32, matrix)]\nInputs shapes: [(25088, 4), (4, 4096)]\nInputs strides: [(4, 100352), (16384, 4)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuElemwise{Composite{((i0 * i1) + (i2 * sqr(i3)))}}[(0, 1)]<gpuarray>(InplaceGpuDimShuffle{x,x}.0, training/Adam/variable, InplaceGpuDimShuffle{x,x}.0, GpuDot22.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/keras/optimizers.py\", line 73, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 1237, in gradients\n    return T.grad(loss, variables)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 605, in grad\n    grad_dict, wrt, cost_name)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1371, in _populate_grad_dict\n    rval = [access_grad_cache(elem) for elem in wrt]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1326, in access_grad_cache\n    term = access_term_cache(node)[idx]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1021, in access_term_cache\n    output_grads = [access_grad_cache(var) for var in node.outputs]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1326, in access_grad_cache\n    term = access_term_cache(node)[idx]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1162, in access_term_cache\n    new_output_grads)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/keras/optimizers.py\", line 73, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py\", line 1237, in gradients\n    return T.grad(loss, variables)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 605, in grad\n    grad_dict, wrt, cost_name)\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1371, in _populate_grad_dict\n    rval = [access_grad_cache(elem) for elem in wrt]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1326, in access_grad_cache\n    term = access_term_cache(node)[idx]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1021, in access_term_cache\n    output_grads = [access_grad_cache(var) for var in node.outputs]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1326, in access_grad_cache\n    term = access_term_cache(node)[idx]\n  File \"/home/callum/anaconda2/lib/python2.7/site-packages/theano/gradient.py\", line 1162, in access_term_cache\n    new_output_grads)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "#Fit Model\n",
    "#model.load_weights('models/dogscats2.h5')\n",
    "\n",
    "fake_model.fit_generator(train_batches, steps_per_epoch=int(np.ceil(train_batches.samples/batch_size)), epochs=1,\n",
    "                validation_data=val_batches, validation_steps=int(np.ceil(val_batches.samples/batch_size)))\n",
    "#model.fit_generator(train_batches, samples_per_epoch=train_batches.samples, epochs=1, validation_data=val_batches, validation_steps=val_batches.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('models/dogscats2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Examine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=4, linewidth=100)\n",
    "import matplotlib.pyplot as plt\n",
    "#Use the plots helper function\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sample_batches = gen.flow_from_directory(train_path, target_size=(224,224), class_mode='categorical', shuffle=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get a few images and their true labels\n",
    "imgs, labels = next(sample_batches)\n",
    "indxs = np.argmax(labels, axis=1)\n",
    "indxs\n",
    "labels = [classes[indx] for indx in indxs]\n",
    "true_labels_dict = {\n",
    "    'c0': 'safe driving',\n",
    "    'c1': 'texting - right',\n",
    "    'c2': 'talking on the phone - right',\n",
    "    'c3': 'texting - left',\n",
    "    'c4': 'talking on the phone - left',\n",
    "    'c5': 'operating the radio',\n",
    "    'c6': 'drinking',\n",
    "    'c7': 'reaching behind',\n",
    "    'c8': 'hair and makeup',\n",
    "    'c9': 'talking to passenger',\n",
    "}\n",
    "true_labels = [true_labels_dict[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plots(imgs, titles=true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('models/state_farm.h5')\n",
    "batches = gen.flow_from_directory(path+'/test', target_size=(224,224), class_mode='categorical', shuffle=True, batch_size=20)\n",
    "preds = []\n",
    "for i in range(batches.samples):\n",
    "    print i, '/', batches.samples\n",
    "    ims, labs = batches.next()\n",
    "    pred = model.predict(ims)\n",
    "    if preds == []: preds = pred\n",
    "    preds = np.append(preds, pred, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
